## 取り組んだ課題一覧
- 米国AI開発者がゼロから教えるDocker講座(セクション8：59まで)

## わかったこと
- ホストとコンテナの関係について
- `docker run -vホストのパス:コンテナのパス`でファイルシステムのマウントをする（コンテナからホストのファイルを参照できるようにする）※コンテナに含めるとコンテナがどんどん大きくなってしまうため
  - コンテナにフォルダなどが存在しない場合は自動で作成してくれる 
- `id -u`でユーザーIDを確認する,`id -g`でグループIDを確認する
- `docker run -it -u $(id -u):$(id -g) -v マウント元フォルダ:マウント先フォルダ`の` -u $(id -u):$(id -g)`はユーザーIDとグループIDを指定できる
- ユーザーネームはコンテナと共有していないのでi have no name となる
- `-p(パブリッシュ) ホストのポート:コンテナのポート` ホストとコンテナのポートを接続する
- `8888(jupyterのデフォルトポート番号)`
- localhost(ループバックアドレス)
- macのCPU確認 `sysctl -n hw.pyhsicalcpu_max`:物理コア数確認, `sysctl -n hw.logicalcpu_max`:論理コア数確認
- `--cpus`:コンテナの上限CPU設定（ホストの物理コア数を設定）
- `--memory`:コンテナの上限メモリ設定（2g:2GB）
- Dockerを使うメリット:ホストの環境に影響を受けずに環境構築ができる、使い捨ても可能。
- `wget` httpでインターネットからダウンロードしてくる
- `sh`
- `$PATH` 環境変数に指定するディレクトリを追加したい時
- `pip`  pythonのパッケージ管理コマンド
- AWS ECSでインスタンスを起動する（うぶんつ）とユーザーは自動的にubuntuで名前が設定される
- パブリック IPv4 DNSは停止すると変わる
- `docker.io` コミュニティ版のインストールに利用する
- `gpasswd -a ubuntu docker` dockerようグループを用意してubuntuユーザーをdockerにアクセスできるようにした
- ローカルマシンにあるDockerImageをAWSに送る方法
  - Dockerレジストリを使う（DockerHubを経由する）
  - DockerfileをAWS側に送る（ビルドコンテキストに注意が必要）スリム
  - DockerImageをtarにして送る（セキュリティガチガチのサーバはこのパターン、サーバ自体がインターネットにアクセスできないなど）
  - `docker save イメージ > ファイル名.tar` でDockerImageをtarファイルにできる
  - `docker build`するときにtarファイルを戻す環境が異なる場合は環境を指定してbuildしておくと安全
  - SFTP:SecureFileTransferProtocol
    - `put`:送る `put local/パス [remote/パス]`（リモート先を指定しないとカレントディレクトリに配置する）
    - `get`:受け取る `get remote/パス [local/パス]` ローカル先を指定しないと同上
  - `docker load < ファイル名.tar`でtarファイルを戻す
  - `df -h` データファイル `-h`は容量をギガなど整備して表示してくれる
  - Dockerfileを転送する時はSFTPでputでOK
  - Docker daemonの設定を変えられる（linux）

## 次やること
- 米国AI開発者がゼロから教えるDocker講座（続き）
- Docker入門（続き）

## 感じたこと
- M1mac厄介、そしてコンテナすごい

## 学習時間
- 　Today：6h
- 　Total：157.5h
